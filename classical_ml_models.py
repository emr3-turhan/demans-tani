#!/usr/bin/env python3
"""
Klasik makine Ã¶ÄŸrenmesi modelleriyle demans tespiti yapan Python scripti
"""

import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif, RFE
import pickle
import warnings
warnings.filterwarnings('ignore')

from feature_extraction import AudioFeatureExtractor

class ClassicalMLDemantiaDetector:
    """Klasik makine Ã¶ÄŸrenmesi yÃ¶ntemleriyle demans tespit sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        """SÄ±nÄ±fÄ± baÅŸlatÄ±r"""
        self.feature_extractor = AudioFeatureExtractor()
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_selector = None
        self.best_model = None
        self.best_model_name = None
        
    def prepare_features_and_labels(self, data_directory, labels_csv):
        """
        Ã–zellik Ã§Ä±karÄ±mÄ± ve etiket hazÄ±rlÄ±ÄŸÄ± yapar
        
        Args:
            data_directory (str): Ses dosyalarÄ±nÄ±n bulunduÄŸu dizin
            labels_csv (str): Etiketlerin bulunduÄŸu CSV dosyasÄ±
            
        Returns:
            tuple: (features_df, labels)
        """
        print("ğŸµ Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
        
        # Ã–zellik Ã§Ä±karÄ±mÄ±
        features_df = self.feature_extractor.process_dataset(data_directory)
        
        if features_df is None:
            raise ValueError("Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸarÄ±sÄ±z!")
        
        # Etiketleri yÃ¼kle
        if not Path(labels_csv).exists():
            raise ValueError(f"Etiket dosyasÄ± bulunamadÄ±: {labels_csv}")
        
        labels_df = pd.read_csv(labels_csv)
        print(f"ğŸ“‹ Etiketler yÃ¼klendi: {labels_csv}")
        
        # Dosya adlarÄ± ile etiketleri eÅŸleÅŸtir
        labels_dict = {}
        for _, row in labels_df.iterrows():
            filename = Path(row['filename']).stem
            label = row['label']
            labels_dict[filename] = label
        
        # Etiketleri features_df'e ekle
        matched_labels = []
        matched_indices = []
        
        for idx, row in features_df.iterrows():
            file_path = Path(row['file_path'])
            filename = file_path.stem
            
            if filename in labels_dict:
                matched_labels.append(labels_dict[filename])
                matched_indices.append(idx)
            else:
                # Dosya adÄ±ndan otomatik etiket Ã§Ä±karmayÄ± dene
                filename_lower = filename.lower()
                if 'normal' in filename_lower or 'healthy' in filename_lower:
                    matched_labels.append('Normal')
                    matched_indices.append(idx)
                elif 'mci' in filename_lower or 'mild' in filename_lower:
                    matched_labels.append('MCI')
                    matched_indices.append(idx)
                elif 'dementia' in filename_lower or 'alzheimer' in filename_lower:
                    matched_labels.append('Dementia')
                    matched_indices.append(idx)
        
        # Sadece eÅŸleÅŸen Ã¶rnekleri al
        features_df = features_df.iloc[matched_indices].reset_index(drop=True)
        labels = np.array(matched_labels)
        
        print(f"ğŸ“Š Veri eÅŸleÅŸtirmesi tamamlandÄ±:")
        print(f"   - Toplam Ã¶rnek sayÄ±sÄ±: {len(features_df)}")
        print(f"   - Etiket daÄŸÄ±lÄ±mÄ±: {np.unique(labels, return_counts=True)}")
        
        return features_df, labels
    
    def preprocess_features(self, features_df):
        """
        Ã–zellikleri Ã¶n iÅŸleme yapar
        
        Args:
            features_df (pandas.DataFrame): Ã–zellik DataFrame'i
            
        Returns:
            numpy.array: Ä°ÅŸlenmiÅŸ Ã¶zellik matrisi
        """
        # Numerik olmayan sÃ¼tunlarÄ± Ã§Ä±kar
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        feature_matrix = features_df[numeric_columns].values
        
        # NaN deÄŸerleri median ile doldur
        from sklearn.impute import SimpleImputer
        imputer = SimpleImputer(strategy='median')
        feature_matrix = imputer.fit_transform(feature_matrix)
        
        # Sonsuz deÄŸerleri kaldÄ±r
        feature_matrix = np.nan_to_num(feature_matrix, nan=0.0, posinf=0.0, neginf=0.0)
        
        print(f"ğŸ”§ Ã–zellik matrisi hazÄ±rlandÄ±: {feature_matrix.shape}")
        
        return feature_matrix, numeric_columns.tolist()
    
    def feature_selection(self, X, y, method='univariate', k=50):
        """
        Ã–zellik seÃ§imi yapar
        
        Args:
            X (numpy.array): Ã–zellik matrisi
            y (numpy.array): Etiketler
            method (str): SeÃ§im yÃ¶ntemi ('univariate', 'rfe')
            k (int): SeÃ§ilecek Ã¶zellik sayÄ±sÄ±
            
        Returns:
            numpy.array: SeÃ§ilmiÅŸ Ã¶zellikler
        """
        print(f"ğŸ¯ Ã–zellik seÃ§imi yapÄ±lÄ±yor: {method}")
        
        if method == 'univariate':
            self.feature_selector = SelectKBest(score_func=f_classif, k=min(k, X.shape[1]))
        elif method == 'rfe':
            estimator = RandomForestClassifier(n_estimators=50, random_state=42)
            self.feature_selector = RFE(estimator, n_features_to_select=min(k, X.shape[1]))
        else:
            raise ValueError(f"Desteklenmeyen Ã¶zellik seÃ§imi yÃ¶ntemi: {method}")
        
        # Etiketleri encode et
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Ã–zellik seÃ§imi uygula
        X_selected = self.feature_selector.fit_transform(X, y_encoded)
        
        print(f"âœ… {X.shape[1]} Ã¶zellikten {X_selected.shape[1]} tanesi seÃ§ildi")
        
        return X_selected
    
    def initialize_models(self):
        """Model sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ baÅŸlatÄ±r"""
        self.models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'SVM': SVC(kernel='rbf', probability=True, random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'NaiveBayes': GaussianNB()
        }
    
    def train_and_evaluate_models(self, X, y, test_size=0.2, cv_folds=5):
        """
        TÃ¼m modelleri eÄŸitir ve deÄŸerlendirir
        
        Args:
            X (numpy.array): Ã–zellik matrisi
            y (numpy.array): Etiketler
            test_size (float): Test veri oranÄ±
            cv_folds (int): Cross-validation fold sayÄ±sÄ±
            
        Returns:
            dict: Model performans sonuÃ§larÄ±
        """
        print("ğŸš€ Model eÄŸitimi ve deÄŸerlendirmesi baÅŸlÄ±yor...")
        
        # Etiketleri encode et
        y_encoded = self.label_encoder.transform(y)
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded
        )
        
        # Feature scaling
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        results = {}
        
        for model_name, model in self.models.items():
            print(f"\nğŸ“Š {model_name} eÄŸitiliyor...")
            
            # Cross-validation
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv_folds, scoring='accuracy')
            
            # Model eÄŸitimi
            model.fit(X_train_scaled, y_train)
            
            # Test tahmini
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None
            
            # Performans metrikleri
            accuracy = model.score(X_test_scaled, y_test)
            
            # Classification report
            target_names = self.label_encoder.classes_
            class_report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
            
            # Confusion matrix
            conf_matrix = confusion_matrix(y_test, y_pred)
            
            # ROC AUC (multi-class iÃ§in macro average)
            roc_auc = None
            if y_pred_proba is not None and len(np.unique(y_encoded)) > 2:
                roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')
            elif y_pred_proba is not None and len(np.unique(y_encoded)) == 2:
                roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])
            
            results[model_name] = {
                'model': model,
                'cv_scores': cv_scores,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'test_accuracy': accuracy,
                'classification_report': class_report,
                'confusion_matrix': conf_matrix,
                'roc_auc': roc_auc
            }
            
            print(f"   CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
            print(f"   Test Accuracy: {accuracy:.4f}")
            if roc_auc:
                print(f"   ROC AUC: {roc_auc:.4f}")
        
        # En iyi modeli seÃ§
        best_accuracy = 0
        for model_name, result in results.items():
            if result['test_accuracy'] > best_accuracy:
                best_accuracy = result['test_accuracy']
                self.best_model = result['model']
                self.best_model_name = model_name
        
        print(f"\nğŸ† En iyi model: {self.best_model_name} (Accuracy: {best_accuracy:.4f})")
        
        return results
    
    def hyperparameter_tuning(self, X, y, model_name='RandomForest'):
        """
        Hiperparametre optimizasyonu yapar
        
        Args:
            X (numpy.array): Ã–zellik matrisi
            y (numpy.array): Etiketler
            model_name (str): Optimize edilecek model
            
        Returns:
            dict: En iyi parametreler ve sonuÃ§lar
        """
        print(f"ğŸ”§ {model_name} iÃ§in hiperparametre optimizasyonu...")
        
        y_encoded = self.label_encoder.transform(y)
        X_scaled = self.scaler.transform(X)
        
        param_grids = {
            'RandomForest': {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            },
            'SVM': {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],
                'kernel': ['rbf', 'linear']
            },
            'LogisticRegression': {
                'C': [0.01, 0.1, 1, 10, 100],
                'solver': ['liblinear', 'saga'],
                'penalty': ['l1', 'l2']
            }
        }
        
        if model_name not in param_grids:
            print(f"âŒ {model_name} iÃ§in parametre grid'i tanÄ±mlanmamÄ±ÅŸ")
            return None
        
        model = self.models[model_name]
        param_grid = param_grids[model_name]
        
        # Grid search
        grid_search = GridSearchCV(
            model, param_grid, cv=5, scoring='accuracy', 
            n_jobs=-1, verbose=1
        )
        
        grid_search.fit(X_scaled, y_encoded)
        
        result = {
            'best_params': grid_search.best_params_,
            'best_score': grid_search.best_score_,
            'best_model': grid_search.best_estimator_
        }
        
        print(f"âœ… En iyi parametreler: {result['best_params']}")
        print(f"âœ… En iyi CV score: {result['best_score']:.4f}")
        
        # En iyi modeli gÃ¼ncelle
        self.models[model_name] = result['best_model']
        
        return result
    
    def plot_results(self, results, save_path=None):
        """
        SonuÃ§larÄ± gÃ¶rselleÅŸtirir
        
        Args:
            results (dict): Model sonuÃ§larÄ±
            save_path (str, optional): Grafiklerin kaydedileceÄŸi dizin
        """
        # Model karÅŸÄ±laÅŸtÄ±rmasÄ±
        model_names = list(results.keys())
        accuracies = [results[name]['test_accuracy'] for name in model_names]
        cv_means = [results[name]['cv_mean'] for name in model_names]
        cv_stds = [results[name]['cv_std'] for name in model_names]
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Model accuracy karÅŸÄ±laÅŸtÄ±rmasÄ±
        axes[0, 0].bar(model_names, accuracies, color='skyblue', alpha=0.7)
        axes[0, 0].set_title('Model Test Accuracy KarÅŸÄ±laÅŸtÄ±rmasÄ±')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].set_ylim(0, 1)
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        for i, acc in enumerate(accuracies):
            axes[0, 0].text(i, acc + 0.01, f'{acc:.3f}', ha='center')
        
        # 2. Cross-validation sonuÃ§larÄ±
        axes[0, 1].errorbar(model_names, cv_means, yerr=cv_stds, 
                           fmt='o-', capsize=5, capthick=2)
        axes[0, 1].set_title('Cross-Validation SonuÃ§larÄ±')
        axes[0, 1].set_ylabel('CV Accuracy')
        axes[0, 1].set_ylim(0, 1)
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. En iyi modelin confusion matrix'i
        best_result = results[self.best_model_name]
        conf_matrix = best_result['confusion_matrix']
        target_names = self.label_encoder.classes_
        
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                   xticklabels=target_names, yticklabels=target_names,
                   ax=axes[1, 0])
        axes[1, 0].set_title(f'{self.best_model_name} - Confusion Matrix')
        axes[1, 0].set_ylabel('GerÃ§ek')
        axes[1, 0].set_xlabel('Tahmin')
        
        # 4. ROC AUC karÅŸÄ±laÅŸtÄ±rmasÄ± (varsa)
        roc_aucs = [results[name]['roc_auc'] for name in model_names if results[name]['roc_auc'] is not None]
        valid_models = [name for name in model_names if results[name]['roc_auc'] is not None]
        
        if roc_aucs:
            axes[1, 1].bar(valid_models, roc_aucs, color='lightcoral', alpha=0.7)
            axes[1, 1].set_title('ROC AUC KarÅŸÄ±laÅŸtÄ±rmasÄ±')
            axes[1, 1].set_ylabel('ROC AUC')
            axes[1, 1].set_ylim(0, 1)
            axes[1, 1].tick_params(axis='x', rotation=45)
            
            for i, auc in enumerate(roc_aucs):
                axes[1, 1].text(i, auc + 0.01, f'{auc:.3f}', ha='center')
        else:
            axes[1, 1].text(0.5, 0.5, 'ROC AUC\nHesaplanamadÄ±', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('ROC AUC')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(f'{save_path}/model_comparison.png', dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Grafik kaydedildi: {save_path}/model_comparison.png")
        
        plt.show()
    
    def predict(self, audio_file):
        """
        Tek bir ses dosyasÄ± iÃ§in tahmin yapar
        
        Args:
            audio_file (str): Ses dosyasÄ±nÄ±n yolu
            
        Returns:
            dict: Tahmin sonucu
        """
        if self.best_model is None:
            raise ValueError("Model henÃ¼z eÄŸitilmedi!")
        
        print(f"ğŸ”® Tahmin yapÄ±lÄ±yor: {audio_file}")
        
        # Ã–zellik Ã§Ä±karÄ±mÄ±
        features = self.feature_extractor.extract_all_features(audio_file)
        
        # DataFrame'e Ã§evir ve Ã¶n iÅŸle
        features_df = pd.DataFrame([features])
        feature_matrix, _ = self.preprocess_features(features_df)
        
        # Ã–zellik seÃ§imi uygula (eÄŸer yapÄ±lmÄ±ÅŸsa)
        if self.feature_selector:
            feature_matrix = self.feature_selector.transform(feature_matrix)
        
        # Scaling
        feature_matrix_scaled = self.scaler.transform(feature_matrix)
        
        # Tahmin
        prediction = self.best_model.predict(feature_matrix_scaled)[0]
        probabilities = self.best_model.predict_proba(feature_matrix_scaled)[0]
        
        # Sonucu decode et
        predicted_label = self.label_encoder.inverse_transform([prediction])[0]
        
        # OlasÄ±lÄ±klarÄ± etiketlerle eÅŸleÅŸtir
        prob_dict = {}
        for i, label in enumerate(self.label_encoder.classes_):
            prob_dict[label] = probabilities[i]
        
        result = {
            'file': audio_file,
            'model': self.best_model_name,
            'prediction': predicted_label,
            'confidence': np.max(probabilities),
            'probabilities': prob_dict
        }
        
        print(f"âœ… Tahmin: {predicted_label} (GÃ¼ven: {result['confidence']:.4f})")
        
        return result
    
    def save_model(self, model_path):
        """EÄŸitilmiÅŸ modeli kaydeder"""
        model_data = {
            'best_model': self.best_model,
            'best_model_name': self.best_model_name,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'feature_selector': self.feature_selector,
            'models': self.models
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ’¾ Model kaydedildi: {model_path}")
    
    def load_model(self, model_path):
        """KaydedilmiÅŸ modeli yÃ¼kler"""
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        self.best_model = model_data['best_model']
        self.best_model_name = model_data['best_model_name']
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        self.feature_selector = model_data.get('feature_selector', None)
        self.models = model_data.get('models', {})
        
        print(f"ğŸ“‚ Model yÃ¼klendi: {model_path}")
        print(f"ğŸ† En iyi model: {self.best_model_name}")

def main():
    """Ana fonksiyon"""
    import sys
    
    if len(sys.argv) < 2:
        print("Klasik ML Demans Tespit Sistemi")
        print("KullanÄ±m:")
        print("  EÄŸitim: python classical_ml_models.py train /ses/dizini labels.csv")
        print("  Tahmin: python classical_ml_models.py predict model.pkl ses_dosyasi.wav")
        print("  Hiperparametre: python classical_ml_models.py tune /ses/dizini labels.csv RandomForest")
        return
    
    command = sys.argv[1]
    detector = ClassicalMLDemantiaDetector()
    
    if command == "train":
        if len(sys.argv) < 4:
            print("âŒ Ses dizini ve etiket dosyasÄ± belirtiniz!")
            return
        
        data_dir = sys.argv[2]
        labels_file = sys.argv[3]
        
        # Modelleri baÅŸlat
        detector.initialize_models()
        
        # Veri hazÄ±rlÄ±ÄŸÄ±
        features_df, labels = detector.prepare_features_and_labels(data_dir, labels_file)
        feature_matrix, feature_names = detector.preprocess_features(features_df)
        
        # Ã–zellik seÃ§imi
        feature_matrix_selected = detector.feature_selection(feature_matrix, labels)
        
        # Model eÄŸitimi
        results = detector.train_and_evaluate_models(feature_matrix_selected, labels)
        
        # SonuÃ§larÄ± gÃ¶rselleÅŸtir
        detector.plot_results(results, save_path='.')
        
        # Modeli kaydet
        model_name = f"classical_dementia_model.pkl"
        detector.save_model(model_name)
    
    elif command == "predict":
        if len(sys.argv) < 4:
            print("âŒ Model dosyasÄ± ve ses dosyasÄ± belirtiniz!")
            return
        
        model_file = sys.argv[2]
        audio_file = sys.argv[3]
        
        # Modeli yÃ¼kle
        detector.load_model(model_file)
        
        # Tahmin yap
        result = detector.predict(audio_file)
        
        print(f"\nğŸ¯ Tahmin Sonucu:")
        print(f"   Dosya: {result['file']}")
        print(f"   Model: {result['model']}")
        print(f"   Tahmin: {result['prediction']}")
        print(f"   GÃ¼ven: {result['confidence']:.4f}")
        print(f"   OlasÄ±lÄ±klar:")
        for label, prob in result['probabilities'].items():
            print(f"     {label}: {prob:.4f}")
    
    elif command == "tune":
        if len(sys.argv) < 5:
            print("âŒ Ses dizini, etiket dosyasÄ± ve model adÄ± belirtiniz!")
            return
        
        data_dir = sys.argv[2]
        labels_file = sys.argv[3]
        model_name = sys.argv[4]
        
        # Modelleri baÅŸlat
        detector.initialize_models()
        
        # Veri hazÄ±rlÄ±ÄŸÄ±
        features_df, labels = detector.prepare_features_and_labels(data_dir, labels_file)
        feature_matrix, feature_names = detector.preprocess_features(features_df)
        feature_matrix_selected = detector.feature_selection(feature_matrix, labels)
        
        # Hiperparametre optimizasyonu
        result = detector.hyperparameter_tuning(feature_matrix_selected, labels, model_name)
        
        if result:
            print(f"\nğŸ¯ Optimizasyon Sonucu:")
            print(f"   En iyi parametreler: {result['best_params']}")
            print(f"   En iyi CV score: {result['best_score']:.4f}")
    
    else:
        print(f"âŒ Bilinmeyen komut: {command}")

if __name__ == "__main__":
    main() 