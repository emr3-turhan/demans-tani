#!/usr/bin/env python3
"""
Wav2Vec2 modeli kullanarak demans tespiti yapan Python scripti
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from pathlib import Path
from transformers import Wav2Vec2Processor, Wav2Vec2Model
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler, LabelEncoder
import librosa
import pickle
import warnings
warnings.filterwarnings('ignore')

from audio_converter import convert_m4a_to_wav

class Wav2VecDemantiaDetector:
    """Wav2Vec2 tabanlÄ± demans tespit sÄ±nÄ±fÄ±"""
    
    def __init__(self, model_name="facebook/wav2vec2-base"):
        """
        Wav2Vec2 modelini baÅŸlatÄ±r
        
        Args:
            model_name (str): KullanÄ±lacak pre-trained model
        """
        print(f"ğŸ¤– Wav2Vec2 model yÃ¼kleniyor: {model_name}")
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ Cihaz: {self.device}")
        
        # Wav2Vec2 model ve processor'Ä± yÃ¼kle
        self.processor = Wav2Vec2Processor.from_pretrained(model_name)
        self.wav2vec_model = Wav2Vec2Model.from_pretrained(model_name).to(self.device)
        
        # Klasifikasyon modeli
        self.classifier = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        
        print("âœ… Model hazÄ±r!")
    
    def load_and_preprocess_audio(self, file_path, target_sr=16000):
        """
        Ses dosyasÄ±nÄ± yÃ¼kler ve Wav2Vec2 iÃ§in hazÄ±rlar
        
        Args:
            file_path (str): Ses dosyasÄ±nÄ±n yolu
            target_sr (int): Hedef sampling rate
            
        Returns:
            numpy.array: Preprocessed audio
        """
        file_path = Path(file_path)
        
        # .m4a dosyalarÄ±nÄ± .wav'a Ã§evir
        if file_path.suffix.lower() == '.m4a':
            print(f"ğŸ”„ .m4a dosyasÄ± .wav'a Ã§evriliyor: {file_path}")
            wav_path = convert_m4a_to_wav(str(file_path))
            if wav_path:
                file_path = Path(wav_path)
            else:
                raise ValueError(f"Dosya Ã§evrilemedi: {file_path}")
        
        # Ses dosyasÄ±nÄ± yÃ¼kle
        audio, sr = librosa.load(str(file_path), sr=target_sr)
        
        # Wav2Vec2 iÃ§in normalize et
        audio = audio / np.max(np.abs(audio))  # Normalize
        
        return audio
    
    def extract_wav2vec_embeddings(self, audio_array):
        """
        Wav2Vec2 embeddings Ã§Ä±karÄ±r
        
        Args:
            audio_array (numpy.array): Audio waveform
            
        Returns:
            numpy.array: Wav2Vec2 embeddings
        """
        # Processor ile input hazÄ±rla
        inputs = self.processor(
            audio_array, 
            sampling_rate=16000, 
            return_tensors="pt", 
            padding=True
        )
        
        # GPU'ya taÅŸÄ±
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # Model ile embeddings Ã§Ä±kar
        with torch.no_grad():
            outputs = self.wav2vec_model(**inputs)
            
        # Son hidden state'i al ve pool et
        last_hidden_states = outputs.last_hidden_state  # (batch, time, features)
        
        # Global average pooling
        embeddings = torch.mean(last_hidden_states, dim=1)  # (batch, features)
        
        return embeddings.cpu().numpy()
    
    def process_audio_file(self, file_path):
        """
        Tek bir ses dosyasÄ±nÄ± iÅŸler ve embeddings Ã§Ä±karÄ±r
        
        Args:
            file_path (str): Ses dosyasÄ±nÄ±n yolu
            
        Returns:
            numpy.array: Feature vector
        """
        print(f"ğŸµ Ä°ÅŸleniyor: {file_path}")
        
        # Ses dosyasÄ±nÄ± yÃ¼kle
        audio = self.load_and_preprocess_audio(file_path)
        
        # Wav2Vec2 embeddings Ã§Ä±kar
        embeddings = self.extract_wav2vec_embeddings(audio)
        
        return embeddings.flatten()
    
    def prepare_dataset(self, data_directory, labels_csv=None):
        """
        Veri setini hazÄ±rlar
        
        Args:
            data_directory (str): Ses dosyalarÄ±nÄ±n bulunduÄŸu dizin
            labels_csv (str, optional): Etiketlerin bulunduÄŸu CSV dosyasÄ±
            
        Returns:
            tuple: (features, labels) veya sadece features
        """
        data_path = Path(data_directory)
        
        if not data_path.exists():
            raise ValueError(f"Dizin bulunamadÄ±: {data_directory}")
        
        # Ses dosyalarÄ±nÄ± bul
        audio_extensions = ['.wav', '.m4a', '.mp3', '.flac']
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(list(data_path.glob(f"*{ext}")))
            audio_files.extend(list(data_path.glob(f"*{ext.upper()}")))
        
        if not audio_files:
            raise ValueError(f"Ses dosyasÄ± bulunamadÄ±: {data_directory}")
        
        print(f"ğŸ“ {len(audio_files)} ses dosyasÄ± bulundu")
        
        # Etiketleri yÃ¼kle (varsa)
        labels_dict = {}
        if labels_csv and Path(labels_csv).exists():
            labels_df = pd.read_csv(labels_csv)
            print(f"ğŸ“‹ Etiketler yÃ¼klendi: {labels_csv}")
            
            # Dosya adÄ± ve etiket mapping'i oluÅŸtur
            for _, row in labels_df.iterrows():
                filename = Path(row['filename']).stem  # Extension olmadan
                label = row['label']
                labels_dict[filename] = label
        
        # Feature extraction
        features = []
        labels = []
        processed_files = []
        
        for i, audio_file in enumerate(audio_files, 1):
            print(f"[{i}/{len(audio_files)}] Ä°ÅŸleniyor: {audio_file.name}")
            
            try:
                # Embeddings Ã§Ä±kar
                embedding = self.process_audio_file(audio_file)
                features.append(embedding)
                processed_files.append(audio_file.name)
                
                # Etiket varsa ekle
                if labels_dict:
                    filename_stem = audio_file.stem
                    if filename_stem in labels_dict:
                        labels.append(labels_dict[filename_stem])
                    else:
                        # Dosya adÄ±ndan otomatik etiket Ã§Ä±karmayÄ± dene
                        filename_lower = filename_stem.lower()
                        if 'normal' in filename_lower or 'healthy' in filename_lower:
                            labels.append('Normal')
                        elif 'mci' in filename_lower or 'mild' in filename_lower:
                            labels.append('MCI')
                        elif 'dementia' in filename_lower or 'alzheimer' in filename_lower:
                            labels.append('Dementia')
                        else:
                            labels.append('Unknown')
                
            except Exception as e:
                print(f"âŒ Hata: {audio_file.name} - {str(e)}")
                continue
        
        if not features:
            raise ValueError("HiÃ§bir dosya iÅŸlenemedi!")
        
        features = np.array(features)
        
        print(f"\nğŸ“Š Veri seti hazÄ±rlandÄ±:")
        print(f"   - Ä°ÅŸlenen dosya sayÄ±sÄ±: {len(features)}")
        print(f"   - Feature boyutu: {features.shape[1]}")
        
        if labels:
            labels = np.array(labels)
            print(f"   - Etiket daÄŸÄ±lÄ±mÄ±: {np.unique(labels, return_counts=True)}")
            return features, labels, processed_files
        else:
            return features, None, processed_files
    
    def train_classifier(self, features, labels, model_type='random_forest', test_size=0.2):
        """
        Klasifikasyon modelini eÄŸitir
        
        Args:
            features (numpy.array): Feature matrix
            labels (numpy.array): Labels
            model_type (str): Model tÃ¼rÃ¼ ('random_forest', 'svm', 'logistic')
            test_size (float): Test veri oranÄ±
            
        Returns:
            dict: EÄŸitim sonuÃ§larÄ±
        """
        if labels is None:
            raise ValueError("Etiketler bulunamadÄ±! EÄŸitim iÃ§in etiketler gerekli.")
        
        print(f"ğŸ¯ Model eÄŸitiliyor: {model_type}")
        
        # Etiketleri encode et
        labels_encoded = self.label_encoder.fit_transform(labels)
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels_encoded, test_size=test_size, random_state=42, stratify=labels_encoded
        )
        
        # Feature scaling
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Model seÃ§imi
        if model_type == 'random_forest':
            self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_type == 'svm':
            self.classifier = SVC(kernel='rbf', probability=True, random_state=42)
        elif model_type == 'logistic':
            self.classifier = LogisticRegression(random_state=42, max_iter=1000)
        else:
            raise ValueError(f"Desteklenmeyen model tÃ¼rÃ¼: {model_type}")
        
        # EÄŸitim
        print("ğŸ“š Model eÄŸitiliyor...")
        self.classifier.fit(X_train_scaled, y_train)
        
        # Test
        print("ğŸ§ª Model test ediliyor...")
        y_pred = self.classifier.predict(X_test_scaled)
        
        # SonuÃ§larÄ± deÄŸerlendir
        target_names = self.label_encoder.classes_
        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
        
        results = {
            'model_type': model_type,
            'accuracy': report['accuracy'],
            'classification_report': classification_report(y_test, y_pred, target_names=target_names),
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'feature_importance': None
        }
        
        # Feature importance (Random Forest iÃ§in)
        if model_type == 'random_forest':
            results['feature_importance'] = self.classifier.feature_importances_
        
        print(f"\nğŸ“ˆ EÄŸitim TamamlandÄ±!")
        print(f"DoÄŸruluk: {results['accuracy']:.4f}")
        print("\nKlasifikasyon Raporu:")
        print(results['classification_report'])
        
        return results
    
    def predict(self, audio_file):
        """
        Tek bir ses dosyasÄ± iÃ§in tahmin yapar
        
        Args:
            audio_file (str): Ses dosyasÄ±nÄ±n yolu
            
        Returns:
            dict: Tahmin sonucu
        """
        if self.classifier is None:
            raise ValueError("Model henÃ¼z eÄŸitilmedi! Ã–nce train_classifier() Ã§aÄŸÄ±rÄ±n.")
        
        print(f"ğŸ”® Tahmin yapÄ±lÄ±yor: {audio_file}")
        
        # Feature extraction
        features = self.process_audio_file(audio_file)
        features = features.reshape(1, -1)  # Single sample iÃ§in reshape
        
        # Scaling
        features_scaled = self.scaler.transform(features)
        
        # Tahmin
        prediction = self.classifier.predict(features_scaled)[0]
        probabilities = self.classifier.predict_proba(features_scaled)[0]
        
        # Sonucu decode et
        predicted_label = self.label_encoder.inverse_transform([prediction])[0]
        
        # OlasÄ±lÄ±klarÄ± etiketlerle eÅŸleÅŸtir
        prob_dict = {}
        for i, label in enumerate(self.label_encoder.classes_):
            prob_dict[label] = probabilities[i]
        
        result = {
            'file': audio_file,
            'prediction': predicted_label,
            'confidence': np.max(probabilities),
            'probabilities': prob_dict
        }
        
        print(f"âœ… Tahmin: {predicted_label} (GÃ¼ven: {result['confidence']:.4f})")
        
        return result
    
    def save_model(self, model_path):
        """EÄŸitilmiÅŸ modeli kaydeder"""
        model_data = {
            'classifier': self.classifier,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ’¾ Model kaydedildi: {model_path}")
    
    def load_model(self, model_path):
        """KaydedilmiÅŸ modeli yÃ¼kler"""
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        self.classifier = model_data['classifier']
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        
        print(f"ğŸ“‚ Model yÃ¼klendi: {model_path}")

def create_sample_labels_csv():
    """Ã–rnek etiket dosyasÄ± oluÅŸturur"""
    sample_data = {
        'filename': [
            'normal_001.wav',
            'normal_002.wav', 
            'mci_001.wav',
            'mci_002.wav',
            'dementia_001.wav',
            'dementia_002.wav'
        ],
        'label': [
            'Normal',
            'Normal',
            'MCI', 
            'MCI',
            'Dementia',
            'Dementia'
        ]
    }
    
    df = pd.DataFrame(sample_data)
    df.to_csv('sample_labels.csv', index=False)
    print("ğŸ“„ Ã–rnek etiket dosyasÄ± oluÅŸturuldu: sample_labels.csv")

def main():
    """Ana fonksiyon"""
    import sys
    
    if len(sys.argv) < 2:
        print("Wav2Vec2 Demans Tespit Sistemi")
        print("KullanÄ±m:")
        print("  EÄŸitim: python wav2vec_model.py train /ses/dizini labels.csv")
        print("  Tahmin: python wav2vec_model.py predict model.pkl ses_dosyasi.wav")
        print("  Ã–rnek etiket dosyasÄ±: python wav2vec_model.py create_labels")
        return
    
    command = sys.argv[1]
    detector = Wav2VecDemantiaDetector()
    
    if command == "train":
        if len(sys.argv) < 3:
            print("âŒ Ses dizini belirtiniz!")
            return
        
        data_dir = sys.argv[2]
        labels_file = sys.argv[3] if len(sys.argv) > 3 else None
        
        # Veri setini hazÄ±rla
        features, labels, files = detector.prepare_dataset(data_dir, labels_file)
        
        if labels is not None:
            # Model eÄŸit
            results = detector.train_classifier(features, labels)
            
            # Modeli kaydet
            model_name = f"dementia_model_{results['model_type']}.pkl"
            detector.save_model(model_name)
        else:
            print("âš ï¸ Etiketler bulunamadÄ±. Sadece feature extraction yapÄ±ldÄ±.")
    
    elif command == "predict":
        if len(sys.argv) < 4:
            print("âŒ Model dosyasÄ± ve ses dosyasÄ± belirtiniz!")
            return
        
        model_file = sys.argv[2]
        audio_file = sys.argv[3]
        
        # Modeli yÃ¼kle
        detector.load_model(model_file)
        
        # Tahmin yap
        result = detector.predict(audio_file)
        
        print(f"\nğŸ¯ Tahmin Sonucu:")
        print(f"   Dosya: {result['file']}")
        print(f"   Tahmin: {result['prediction']}")
        print(f"   GÃ¼ven: {result['confidence']:.4f}")
        print(f"   OlasÄ±lÄ±klar:")
        for label, prob in result['probabilities'].items():
            print(f"     {label}: {prob:.4f}")
    
    elif command == "create_labels":
        create_sample_labels_csv()
    
    else:
        print(f"âŒ Bilinmeyen komut: {command}")

if __name__ == "__main__":
    main() 